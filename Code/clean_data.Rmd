---
title: "clean_data"
author: "Austin Kennedy"
date: "1/12/2022"
output: html_document
---

```{r Clear memory and setup}
rm(list=ls())
options(scipen=999)
```

```{r Load Packages}
library(tidyverse)
```

```{r Load Data}
# odi1 <- read.csv("../Input/ODI/ODI_1996-2001.csv")
# odi2 <- read.csv("../Input/ODI/ODI_2002-2011.csv")
odi <- read.csv("../Input/ODI/ODI_2002-2011.csv")
fdi <- read.csv("../Input/fdi/fdi_country_industry.csv", nrows = 67, na.strings = "n.s.", check.names = FALSE)
country_safety <- read.csv("../Temporary/country_safety.csv")

#fdi <- read.csv("../Input/us_inward_country.csv", nrows = 65, na.strings = "n.s.", check.names = FALSE)
```

# ```{r Change variable names to match}
# odi1 <- odi1 %>% rename(EMP_Q1 = Q1,
#                         HOURS_Q2 = Q2,
#                         UNUSUAL_Q3 = Q3A,
#                         STRIKE_Q3 = Q3B,
#                         SHUT_Q3 = Q3C,
#                         SEASONAL_Q3 = Q3D,
#                         DISASTER_Q3 = Q3E,
#                         SHORT_Q3 = Q3F,
#                         LONG_Q3 = Q3G,
#                         OREASON_Q3 = Q3H,
#                         )
# ```
```{r ODI data}
#Create two and three digit naics for each firm
odi <- odi %>%
  mutate(naics_2 = as.numeric(substr(NAICS, 1, 2)),
         naics_3 = as.numeric(substr(NAICS, 1, 3)),
         naics_4 = as.numeric(substr(NAICS, 1, 4)),
         naics_5 = as.numeric(substr(NAICS, 1, 5)),
         .before = "EMP_Q1")

odi <- odi %>%
  drop_na(NAICS)

#Generate TCRs
odi <- odi %>%
  mutate(tcr = (INJ_M1*200000) / HOURS_Q2, .before = "EMP_Q1")

```

```{r Clean FDI data}
# fdi <- fdi[,-2] #Second column is the same as the first, but with spacing
colnames(fdi)[1] = "Country"
fdi <- fdi[rowSums(is.na(fdi)) != (ncol(fdi)-1),] #take out rows that have all NAs
fdi$Country <- trimws(fdi$Country) #Remove whitespace
fdi <- fdi[!(fdi$Country %in% c("Addenda:", "Other")),]  #Remove rows that aren't useful
fdi[fdi == "(D)"] <- NA #(D) represents confidential values in the source data
fdi[fdi == "(*)"] <- 0 #(*) represents close to zero in the source data

years <- as.numeric(fdi[2,])
industries <- colnames(fdi)

#Function to insert row
insertRow <- function(existingDF, newrow, r) {
  existingDF[seq(r+1,nrow(existingDF)+1),] <- existingDF[seq(r,nrow(existingDF)),]
  existingDF[r,] <- newrow
  existingDF
}

fdi <- insertRow(fdi, industries, 1) #Insert colnames as a row to not be lost
colnames(fdi) <- years #Change col names to years for wide to long transition

fdi <- t(fdi) #transpose
#Change col names to countries
countries <- fdi[1,] 
colnames(fdi) <- countries
fdi <- fdi[-1,]

colnames(fdi)[1:3] = c("title_2", "title_3", "Year")
rownames(fdi) <- NULL
fdi <- as_tibble(fdi)
# fdi <- fdi %>% pivot_longer(-c("title_2", "title_3", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
```

```{r Match NAICS codes to fdi industries}
naics <- read.csv("../Input/naics07.csv")
naics <- naics[-1,-1]
colnames(naics) <- c("code", "title_3")
naics <- as_tibble(naics)
naics <- subset(naics, nchar(naics$code) <= 5)
# new <- merge(fdi, naics, by = "title_3")

library(fuzzyjoin)

new <- stringdist_join(fdi, naics,
                by = "title_3",
                mode = "left",
                ignore_case = TRUE,
                method = "jw",
                max_dist = 99,
                distance_col = "dist") %>%
  group_by(title_3.x) %>%
  slice_min(order_by = dist, n = 1)

new <- new[, c("title_2", "title_3.x", "code", "title_3.y", "dist")]
uni <- distinct(new, title_3.x, title_3.y, .keep_all = TRUE)
#Manually recode unmatched industries, probably not best practice but best I can do
uni <- uni %>% mutate(industry = case_when(title_3.x == "All Industries Total" ~ "All Industries Total",
                                           title_3.x == "Depository Institutions" ~ "Credit Intermediation and Related Activities",
                                           title_3.x == "Finance (except depository institutions) and insurance" ~ "Finance and Insurance",
                                           title_3.x == "Other Industries" ~ "Other Industries",
                                           title_3.x == "Other Manufacturing" ~ "Manufacturing",
                                           title_3.x == "Total Manufacturing" ~ "Manufacturing",
                                           TRUE ~ title_3.y))
uni <- merge(uni, naics, by.x = "industry", by.y = "title_3")
fdi <- merge(fdi, uni[, c("code.y","title_3.x")], by.x = "title_3", by.y = "title_3.x", all.x = TRUE)
fdi <- rename(fdi, code = code.y)
# fdi <- fdi[, c("title_2", "title_3", "code", "Year", "Country", "fdi")]
fdi <- fdi %>% select("title_2", "title_3", "code", everything())

#Make country-level fdi data as long as possible
fdi <- fdi %>% pivot_longer(-c("title_2", "title_3","code", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
write.csv(fdi, "../Temporary/fdi_country_year.csv")
```

```{r Import industry-only fdi data}
fdi_ind <- read.csv("../Input/fdi/fdi_total_industry.csv", na.strings = "n.s.", check.names = FALSE)
```

```{r Clean industry fdi data}
# fdi <- fdi[,-2] #Second column is the same as the first, but with spacing
colnames(fdi_ind)[1] <- "industry"
fdi_ind <- fdi_ind[rowSums(is.na(fdi_ind)) != (ncol(fdi_ind)-1),] #take out rows that have all NAs
fdi_ind$industry <- trimws(fdi_ind$industry) #Remove whitespace
fdi_ind <- fdi_ind[!(fdi_ind$industry %in% c("Addendum:", "Other")),]  #Remove rows that aren't useful
fdi_ind[fdi_ind == "(D)"] <- NA #(D) represents confidential values in the source data
fdi_ind[fdi_ind == "(*)"] <- 0 #(*) represents close to zero in the source data

fdi_ind <- fdi_ind %>% pivot_longer(!industry, names_to = "year", values_to = "fdi")
naics <- rename(naics, industry = title_3)
#Match industries to NAICS codes
match <- stringdist_join(fdi_ind, naics, #fuzzy matching
                    by = "industry",
                    mode = "left",
                    ignore_case = TRUE,
                    method = "jw",
                    max_dist = 99,
                    distance_col = "dist") %>%
  group_by(industry.x) %>%
  slice_min(order_by = dist, n = 1)

match <- distinct(match, industry.x, industry.y, .keep_all = TRUE)
match <- match %>% filter(dist < 0.25)

fdi_ind_matched <- merge(fdi_ind, match[, c("code", "industry.x", "industry.y")], by.x = "industry", by.y = "industry.x")

#Uncomment to check how well matching did
  
# unmatched <- match %>% filter(dist > 0.05) %>% select(industry.x, industry.y, dist)
# unmatched <- distinct(unmatched, industry.x, industry.y, .keep_all = TRUE)
# unmatched <- unmatched %>% filter(dist < 0.25) %>% select(industry.x, industry.y, dist)

fdi_ind_matched$code <- as.numeric(fdi_ind_matched$code)
fdi_ind_matched$year <- as.numeric(fdi_ind_matched$year)

#Create lagged FDI
fdi_ind_matched <- fdi_ind_matched %>%
  group_by(code) %>%
  mutate(fdi_l1 = lag(fdi, n=1, order_by = year)) %>%
  mutate(fdi_l2 = lag(fdi, n=2, order_by = year)) %>%
  mutate(fdi_l3 = lag(fdi, n=3, order_by = year)) %>%
  mutate(fdi_l4 = lag(fdi, n=4, order_by = year))

#Export fdi data
# write.csv(fdi_ind_matched, "../Temporary/fdi_industry_year.csv")

```
```{r Match source country injury rates to FDI}
#Make country-level fdi data as long as possible
# fdi <- fdi %>% pivot_longer(-c("title_2", "title_3","code", "Year"), names_to = "Country", values_to = "fdi") #Wide to long
#Convert country safety to per 100 instead of 100,000 for comparisons


country_safety$inj_per100 <- country_safety$rate / 1000

country_safety <- country_safety %>%
  group_by(Year) %>%
  mutate(us_inj = ifelse(any(Country == "United States"), inj_per100[Country == "United States"], NA)) %>%
  ungroup() %>%
  mutate(safe_source = ifelse(inj_per100 <= us_inj, 1, 0))

fdi_safety <- merge(fdi, country_safety, by = c("Country", "Year"))

fdi_safety$fdi <- as.numeric(fdi_safety$fdi)
fdi_safety <- fdi_safety[!is.na(fdi_safety$fdi),]
fdi_safety <- fdi_safety[!(fdi_safety<0),]
fdi_safety <- fdi_safety[!is.na(fdi_safety$rate),]

#create lags
fdi_safety <- fdi_safety %>%
  group_by(Country, code) %>%
  mutate(fdi_l1 = lag(fdi, n=1, order_by = Year)) %>%
  mutate(rate_l1 = lag(rate, n=1, order_by = Year)) %>%
  mutate(fdi_l2 = lag(fdi, n=2, order_by = Year)) %>%
  mutate(rate_l2 = lag(rate, n=2, order_by = Year)) %>%
  mutate(fdi_l3 = lag(fdi, n=3, order_by = Year)) %>%
  mutate(rate_l3 = lag(rate, n=3, order_by = Year)) %>%
  mutate(fdi_l4 = lag(fdi, n=4, order_by = Year)) %>%
  mutate(rate_l4 = lag(rate, n=4, order_by = Year))

```


```{r Merge odi and fdi data}
m_5 <- merge(odi, fdi_ind_matched, by.x = c("Year","naics_5"), by.y = c("year","code"))
a_5 <- anti_join(odi, fdi_ind_matched, by = c("naics_5" = "code" , "Year" = "year"))#find rows that weren't matched

m_4 <- merge(a_5, fdi_ind_matched, by.x = c("Year","naics_4"), by.y = c("year","code")) #merge only unmatched
a_4 <- anti_join(a_5, fdi_ind_matched, by = c("naics_4" = "code" , "Year" = "year"))#find rows that weren't matched
m_3 <- merge(a_4, fdi_ind_matched, by.x = c("Year", "naics_3"), by.y = c("year", "code"))
a_3 <- anti_join(a_4, fdi_ind_matched, by = c("naics_3" = "code" , "Year" = "year"))

m_2 <- merge(a_3, fdi_ind_matched, by.x = c("Year", "naics_2"), by.y = c("year", "code"))

odi_matched <- rbind(m_5,m_4,m_3,m_2)
odi_matched <- odi_matched[order(odi_matched$Year),]

odi_matched <- odi_matched %>% mutate(tcr = (INJ_M1*200000) / HOURS_Q2,
                              .before = "EMP_Q1")

odi_matched$fdi <- as.numeric(odi_matched$fdi)
```

```{r Generate "FDI-exposed" dummies}
ind_exposed <- c(325, 524, 523, 336, 441, 333, 334, 324)

odi_matched <- odi_matched %>%
  mutate(exposed = ifelse(naics_3 %in% ind_exposed, 1, 0))

```

```{r Find FDI-weighted aggregate injury rate}
x <- fdi_safety
x <- x[!is.na(x$fdi),]
x <- x[!is.na(x$rate),]

safety_aggavg <- x %>%
  filter(title_3 == "All Industries Total") %>%
  group_by(Year) %>%
  mutate(fdi_share = fdi/sum(fdi)) %>%
  mutate(inj_weighted = fdi_share*rate) %>%
  summarize(weight_avg = sum(inj_weighted))

#WA Agg injury rate lags
safety_aggavg <- safety_aggavg %>%
  mutate(weight_avg_l1 = lag(weight_avg, n = 1, order_by = Year)) %>%
  mutate(weight_avg_l2 = lag(weight_avg, n = 2, order_by = Year)) %>%
  mutate(weight_avg_l3 = lag(weight_avg, n = 3, order_by = Year)) %>%
  mutate(weight_avg_l4 = lag(weight_avg, n = 4, order_by = Year))
```

```{r Merge industry-odi and agg injury rates}
odi_matched <- merge(odi_matched, safety_aggavg, by = "Year")

#remove NAs
odi_matched <- odi_matched[!is.na(odi_matched$fdi),]
```

```{r Export matched odi data}
write.csv(odi_matched, "../Temporary/odi_fdi.csv", row.names = FALSE)

```

###INDUSTRY-LEVEL AGGREGATION AND SAFETY
```{r Create Baseline Safe/Unsafe}
us_safety <- odi %>%
  filter(Year == 2003) %>%
  summarize(mean(tcr)) %>%
  as.numeric()

industry_safety <- odi %>%
  filter(Year == 2003) %>%
  group_by(NAICS) %>%
  summarize(tcr_avg = mean(tcr)) %>%
  mutate(safe_industry = ifelse(tcr_avg <= us_safety, 1, 0))

state_safety <- odi %>%
  filter(Year == 2003) %>%
  group_by(STATE) %>%
  summarize(tcr_avg = mean(tcr)) %>%
  mutate(safe_state = ifelse(tcr_avg <= us_safety, 1, 0))
```

```{r Create safe, unsafe FDI, relative to the US}
fdi_safe <- fdi_safety %>%
  group_by(Year, code) %>%
  filter(safe_source == 1) %>%
  summarize(fdi_safe = sum(fdi, na.rm=TRUE))

fdi_unsafe <- fdi_safety %>%
  group_by(Year, code) %>%
  filter(safe_source == 0) %>%
  summarize(fdi_unsafe = sum(fdi, na.rm=TRUE))

fdi_safety_shares <- inner_join(fdi_safe, fdi_unsafe, by = c("Year","code")) %>%
  mutate(fdi_total = fdi_safe+fdi_unsafe) %>%
  mutate(safe_share = (fdi_safe/fdi_total)*100) %>%
  filter(safe_share >= 0)

fdi_safety_shares$Year <- as.integer(fdi_safety_shares$Year)
```

```{r Retrieve industry x year fdi from odi data}
fdi_ind_year <- unique(odi_matched[,c('NAICS','naics_3', 'Year', 'fdi')])
fdi_ind_year$naics_3 <- as.character(fdi_ind_year$naics_3)
```

```{r Aggregate industry-year and merge fdi}
ind_year <- odi %>%
  group_by(NAICS, Year) %>%
  summarize(tcr = mean(tcr)) %>%
  left_join(industry_safety[,c('NAICS', 'safe_industry')], by = c('NAICS')) %>%
  left_join(fdi_ind_year, by = c('NAICS', 'Year')) %>%
  left_join(fdi_safety_shares[,c('Year', 'code', 'safe_share')], by = c("naics_3" = "code", 'Year'))

state_ind_year <- odi %>%
  group_by(NAICS, Year, STATE) %>%
  summarize(tcr = mean(tcr)) %>%
  left_join(state_safety[, c('STATE', 'safe_state')], by = c('STATE')) %>%
  left_join(industry_safety[,c('NAICS', 'safe_industry')], by = c('NAICS')) %>%
  left_join(fdi_ind_year, by = c('NAICS', 'Year')) %>%
  left_join(fdi_safety_shares[,c('Year', 'code', 'safe_share')], by = c("naics_3" = "code", 'Year'))
```

```{r Export}
write.csv(ind_year, '../Temporary/industry_agg.csv')
write.csv(state_ind_year, '../Temporary/state_industry_agg.csv')
```


```{r Merge odi and fdi_safety}
#For now, just work with firms that can be matched at the 3-digit level
merge_1 <- merge(odi, fdi_safety, by.x = c("Year","naics_3"), by.y = c("Year","code"))

#Create new var with avg worker injuries by industry and year
merge_1 <- merge_1 %>%
  group_by(naics_3, Year) %>%
  mutate(inj_ind = mean(tcr))

#Create new var with US safety rate by year

us_safety <- country_safety %>%
  filter(Country == "United States")

merge_1 <- merge(merge_1, us_safety[, c("rate", "Year")], by = "Year")

merge_1 <- rename(merge_1,  inj_us = rate.y)
merge_1 <- rename(merge_1, inj_foreign = rate.x)
merge_1$fdi <- as.numeric(merge_1$fdi)

#Export data with source country fdi
# write.csv(merge_1, "../Temporary/odi_fdi_source.csv", row.names = FALSE)

```

```{r Interaction summation and FDI-weighted injury rate}
odi_plant <- merge_1

# yo <- a %>%
#   filter(ESTAB_NAME == "Flowers Bakery of Texarkana, LLC", Country == "Germany")
#remove NAs and negative fdi


#Summed Interaction
interact <- odi_plant %>%
  mutate(interact = inj_foreign*fdi) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  summarize(int_sum = sum(interact, na.rm = TRUE),
            fdi_tot = sum(fdi, na.rm = TRUE))

#FDI-weighted avg
a <- odi_plant %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  mutate(fdi_share = fdi/sum(fdi, na.rm = TRUE)) %>%
  mutate(fdi_share_l1 = fdi_l1/sum(fdi_l1, na.rm=TRUE)) %>%
  mutate(fdi_share_l2 = fdi_l2/sum(fdi_l2, na.rm=TRUE)) %>%
  mutate(fdi_share_l3 = fdi_l3/sum(fdi_l3, na.rm=TRUE)) %>%
  mutate(fdi_share_l4 = fdi_l4/sum(fdi_l4, na.rm=TRUE)) %>%
  mutate(inj_weighted = fdi_share*inj_foreign) %>%
  mutate(inj_weighted_l1 = fdi_share_l1*rate_l1) %>%
  mutate(inj_weighted_l2 = fdi_share_l2*rate_l2) %>%
  mutate(inj_weighted_l3 = fdi_share_l3*rate_l3) %>%
  mutate(inj_weighted_l4 = fdi_share_l4*rate_l4)

wavg_l0 <- a %>%
  summarize(weight_avg = sum(inj_weighted, na.rm = TRUE))
  # summarize(weight_avg = sum(inj_weighted))
wavg_l1 <- a %>%
  summarize(weight_avg_l1 = sum(inj_weighted_l1, na.rm = TRUE))

wavg_l2 <- a %>%
  summarize(weight_avg_l2 = sum(inj_weighted_l2, na.rm = TRUE))

wavg_l3 <- a %>%
  summarize(weight_avg_l3 = sum(inj_weighted_l3, na.rm = TRUE))

wavg_l4 <- a %>%
  summarize(weight_avg_l4 = sum(inj_weighted_l4, na.rm = TRUE))

wavg <- list(wavg_l0, wavg_l1, wavg_l2, wavg_l3, wavg_l4)

wavg <- wavg %>%
  reduce(full_join, by = c("STREET", "Year", "ESTAB_NAME"))


#Yearly world average injury rate
inj_world <- country_safety %>%
  group_by(Year) %>%
  summarize(inj_world = mean(rate))

odi_plant <- merge(odi_plant, inj_world, by = "Year")

#FDI-weighted deviations from world average, summed
dev <- odi_plant %>%
  mutate(dev = inj_foreign - inj_world) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  mutate(fdi_share = fdi/sum(fdi, na.rm = TRUE)) %>%
  summarize(davg = sum(fdi_share*dev))
  


odi_plant <- merge(odi, interact, by = c("STREET", "Year", "ESTAB_NAME"))
odi_plant <- merge(odi_plant, wavg, by = c("STREET", "Year", "ESTAB_NAME"))
odi_plant <- merge(odi_plant, dev, by = c("STREET", "Year", "ESTAB_NAME"))

# wa_lags <- odi_plant %>%
#   group_by(STREET, Year, ESTAB_NAME) %>%
#   mutate(weight_avg_l1 = lag(weight_avg, n=1, order_by = Year)) %>%
#   mutate(weight_avg_l2 = lag(weight_avg, n=2, order_by = Year)) %>%
#   mutate(weight_avg_l3 = lag(weight_avg, n=3, order_by = Year)) %>%
#   mutate(weight_avg_l4 = lag(weight_avg, n=4, order_by = Year)) 
#   
#Export plant-level data
write.csv(odi_plant, "../Temporary/odi_plant.csv")

```

```{r Create Interaction Summation}
odi_plant <- merge_1

#Sum of the interaction of FDI and source injury rate 
odi_plant <- odi_plant %>%
  mutate(interact = inj_foreign*fdi) %>%
  group_by(STREET, Year, ESTAB_NAME) %>%
  summarize(int_sum = sum(interact, na.rm = TRUE),
            fdi_tot = sum(fdi, na.rm = TRUE)) %>%


odi_plant <- merge(odi, odi_plant, by = c("STREET", "Year", "ESTAB_NAME"))


# write.csv(odi_plant, "../Temporary/odi_plant.csv", row.names = FALSE)

```


```{r FDI weighted injuries}

  
```

```{r Find Safe and Unsafe}

# #Find safe and unsafe fdi
# merge_2 <- merge_1 %>% 
#   group_by(STREET, Year) %>%
#   summarize(fdi_safe_us = sum(fdi[which(inj_foreign <= inj_us)], na.rm = TRUE),
#             fdi_unsafe_us = sum(fdi[which(inj_foreign > inj_us)], na.rm = TRUE),
#             fdi_safe_ind = sum(fdi[which(inj_foreign <= inj_ind)], na.rm = TRUE),
#             fdi_unsafe_ind = sum(fdi[which(inj_foreign > inj_ind)], na.rm = TRUE),
#             fdi_safe_plant = sum(fdi[which(inj_foreign <= tcr)], na.rm = TRUE),
#             fdi_unsafe_plant = sum(fdi[which(inj_foreign > tcr)], na.rm = TRUE)
#             )
# 
# #merge odi and safe/unsafe
# odi_final <- merge(odi, merge_2, by = c("STREET", "Year"))

```

```{r Export ODI final}
# write.csv(odi_final, "../Temporary/odi_fdi_safety.csv", row.names = FALSE)

```


```{r Fuzzy matching if data is long}
# naics <- read.csv("../Input/naics07.csv")
# naics <- naics[-1,-1]
# colnames(naics) <- c("code", "title_3")
# naics <- as_tibble(naics)
# naics <- subset(naics, nchar(naics$code) <= 5)
# # new <- merge(fdi, naics, by = "title_3")
# library(fuzzyjoin)
# new <- stringdist_join(fdi, naics,
#                 by = "title_3",
#                 mode = "left",
#                 ignore_case = TRUE,
#                 method = "jw",
#                 max_dist = 99,
#                 distance_col = "dist") %>%
#   group_by(title_3.x) %>%
#   slice_min(order_by = dist, n = 1)
# uni <- distinct(new, title_3.x, title_3.y, .keep_all = TRUE)
# #Manually recode unmatched industries, probably not best practice but best I can do
# uni <- uni %>% mutate(industry = case_when(title_3.x == "All Industries Total" ~ "All Industries Total",
#                                            title_3.x == "Depository Institutions" ~ "Credit Intermediation and Related Activities",
#                                            title_3.x == "Finance (except depository institutions) and insurance" ~ "Finance and Insurance",
#                                            title_3.x == "Other Industries" ~ "Other Industries",
#                                            title_3.x == "Other Manufacturing" ~ "Manufacturing",
#                                            title_3.x == "Total Manufacturing" ~ "Manufacturing",
#                                            TRUE ~ title_3.y))
# uni <- merge(uni, naics, by.x = "industry", by.y = "title_3")
# fdi <- merge(fdi, uni[, c("code.y","title_3.x")], by.x = "title_3", by.y = "title_3.x", all.x = TRUE)
# fdi <- rename(fdi, code = code.y)
# fdi <- fdi[, c("title_2", "title_3", "code", "Year", "Country", "fdi")]
```





```{r Create Plant IDs}
# #Using street addresses because want to identify individual plants instead of firms
# odi <- odi %>%
#   group_by(STREET) %>%
#   mutate(ID = cur_group_id())
# 
# #check no. of unique IDs
# length(unique(odi[["ID"]]))
```

```{r Test code}
uni <- distinct(new, title_3.x, title_3.y)
```



```{r Quick Figs}
library(ggrepel)

#Inward FDI by Country
fdi_all <- fdi 
fdi_all$fdi <- as.numeric(fdi_all$fdi)
fdi_all <- fdi_all %>%
  filter(title_3 == "All Industries Total") 

fdi_avg <- fdi_all%>%
  group_by(Country) %>%
  summarize(avg = mean(fdi, na.rm = TRUE))

fdi_avg <- arrange(fdi_avg, -avg)

countries = list("Ireland", "United Kingdom", "Japan", "Netherlands", "Canada", "Mexico", "France", "Germany", "Switzerland", "Middle East")

years <- seq(1998,2020,2)

fdi_top <- fdi_all %>%
  filter(Country %in% countries) %>%
  mutate(label = if_else(Year == max(Year), as.character(Country), NA_character_))
  # filter(Country == c("China", "United Kingdom", "Japan", "Netherlands", "Canada", "Mexico", "France", "Germany", "Switzerland", "Middle East"))



inward_fdi <- ggplot(fdi_top, aes(x = Year, y = fdi, group = Country, color = Country)) +
  geom_smooth(se = FALSE) +
  geom_label_repel(aes(label = label),
                   nudge_x = 1,
                   na.rm = TRUE) +
  scale_x_discrete(breaks = years) +
  labs(title = "FDI into the US", x = "Year", y = "U.S. Inward FDI, Net Position in Millions of USD") +
  theme(legend.position = "none")
show(inward_fdi)
ggsave("../Output/fdi_country.png")

#Safety by country
fdi_safety_all <- fdi_safety %>%
  filter(title_3 == "All Industries Total")

safety_avg <- fdi_safety_all %>%
  group_by(Country) %>%
  summarize(avg_inj = mean(rate, na.rm = TRUE))

fdi_avg <- fdi_safety_all %>%
  group_by(Country) %>%
  summarize(avg_fdi = mean(fdi, na.rm = TRUE))

country_avg <- merge(safety_avg, fdi_avg, by = "Country")

inj_fdi_scatter <- ggplot(country_avg, aes(x = avg_fdi, y = avg_inj)) +
  geom_point(size = 2, color = "blue") +
  theme(aspect.ratio = 3/4) +
  labs(title = "Source Country FDI vs. Injury Rates", x = "Average FDI, Millions of USD", y = "Average Injury rate per 100 workers")
ggsave("../Output/inj_fdi_scatter.png")

# inward_rates <- ggplot(fdi_safety_all, aes(x = Year, y = rate, group = Country, color = Country)) + geom_smooth(se = FALSE)
# 
# show(inward_rates)

fdi_total_us <- fdi_ind %>%
  filter(industry == "All Industries Total")

fdi_total_us$fdi <- as.numeric(fdi_total_us$fdi)

fdi_time <- ggplot(fdi_total_us, aes(x = year, y = fdi, group=1)) +
  geom_line(color = "blue") + 
  scale_x_discrete(breaks = years) +
  theme(aspect.ratio = 3/4) +
  labs(title = "FDI into the U.S.", y = "Total Net Inward FDI Position, Millions of USD", x = "Year")
ggsave("../Output/fdi_time.png")

#US injury rates over time
inj_avg <- odi_matched %>%
  group_by(Year) %>%
  summarize(inj_avg = mean(tcr, na.rm = TRUE))

inj_time <- ggplot(inj_avg, aes(x = as.character(Year), y = inj_avg, group = 1)) +
  geom_line(size = 1, color = "red") +
  scale_x_discrete(breaks = years) +
  theme(aspect.ratio = 3/4) +
  labs(title = "U.S. Workplace Injury Rates Over Time", x = "Year", y = "Average Total Case Rate (TCR)")

  ggsave("../Output/inj_time.png")
```













